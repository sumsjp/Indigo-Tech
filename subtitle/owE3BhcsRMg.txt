欢迎回到 Indigo Talk
今天我们正好在 NeurIPS 的这个活动快结束了
我这次有两个从硅谷来的好朋友
带领我体验了一下这次神经网络里面的学术会议
我是第一次参加
然后今天我们在周六正好邀请这两个朋友
一块来和大家分享一下
这么四五天左右的所见所闻
在这次活动上的
好吧我觉得我们这个录制应该比较及时
我们还活动是礼拜天结束
然后我们改在礼拜六
但是所有的大佬们的演讲基本上都出现了
而且好的论文也看过了
所以说我今天就邀请这两个朋友
和我一块儿来分享这一次的感受和想法
然后我先介绍一下
在最左边这一位是 Sonya
她来自于 Meta 前 Meta
现在也是准备在硅谷这边来做 Fund 的投资
然后中间这位是 Jay
他现在在硅谷做AI的创业
而且他是怎么说呢
待会儿她自己介绍她的神秘身份
OK 我们介绍一下
因为这里我觉得看人AI的这个paper
Jay是最专业的
因为他过去参加过几次
连续的这个 NeurIPS 的会议
所以说他这次也会带领我们
主要是他带领我
因为我之前没有参加过
第一次参加学术会议
所以说带领我来感受一下这个会议
要不大家自有介绍一下吧
大家好我叫Sonya
然后我之前是在硅谷的一个大厂里面工作
最近的话有做一些创业
然后
有跟朋友想要去做一些fund
然后
然后反正也
结交各种非常有趣的朋友这样子
然后Jay
大家好我叫Jay
然后我目前是在硅谷做AI的创业
平时也会做一些投资
这次非常开心
然后在这边参加 NeurIPS 的时候
碰到了这个 Indigo
所以就巧遇
巧遇
是的是巧遇
其实我们上一次的硅谷约好了
约好了我们说这一次一块来看一下这个活动的
好吧
我介绍一下可能很多人不知道 NeurIPS 是什么
NeurIPS 办了应该有30多年了吧
还是更多
37年的历史
然后这次学术会议
就跟什么理论物理学
什么化学医学这种类似的学术会议一样的
它只是做AI神经网络方面的一个学术会议
然后我记得Jay以前跟我说过
在2014年之前
这个会议才300人参加
就很早的时候
对
我第一次参加这个会还是上2011年的时候
对
那个时候就只有两三百个人
然后到2018年的时候就已经蛮多人了
很多9000个
今年可能有个我没有具体的看过这个统计的数据
但是有可能我觉得应该是有一万多个
根据这个人流来看的话
绝对不止
因为他有好多这个 side events
这个会很多人不参加组合场
因为你要做 social
你主会场没必要
都听学术报告的
大家很多 side event 派对什么东西
我估计有三万人以上
反正就是参与的人数真的是激增
但是 paper 数也是激增
对
今天据说好像有15000多个提交
但录取了可能四五千个
OK
这个是大概吧
大家知道这是一个学术会议
而且这也是现在全世界最火的学术会议了
因为AI这两年太火了
因为 ChatGPT 和 OpenAI
然后在之前其实在2018、2019年
它其实已经比较火了
因為這是上一次AI革命
對叫做我們說圖像識別啊語音識別
然後現在這一次革命就是大语言模型
對我們現在正在這一次革命之中
對這是革命之中
然後呢這個我可以再介紹一下這個
在這個活動上面
我覺得這一次正好有
好幾位大佬是吧
好幾位這個AI界的這個
我們的這個教父和教母
教父沒來就Hinton沒來
Hinton不方便
他不能坐飞机
然后叫教母李飞飞来了
对吧
李飞飞做了一个很精彩的分享
教父的学生来了
对
你可以说是哪一位学生
Ilya 呀，最得意的门生
对吧
对
OpenAI 的前
前 Chef Scientist
现在这个SSI的创始人
对
然后我们还在一个分会场上
看到了Google的CTO
应该是这个头衔
Jeff Dean
Jeff Dean 是 CTO
CTO 应该不算
应该是Chief的
OK
Gemini 的三个 Tech leader 之一
反正是大神
正好我们也
因为以前是 Google Brain 负责人
后来因为这个Google DeepMind 合并了之后
他就有所变化
OK
这个大概的一些背景
就是来了一些什么人
然后上面这个历届的规模是什么样子的
OK
那么我们先来聊一个话题
这是我觉得最意外的是
我觉得是昨天周五
因为我们昨天正好是叫做
叫做终身成就论文颁奖是吧
Test of Time
叫 Test of Time
时间检验奖
这个奖项名字特别好
而且一定是10年
对10年
那么现在是2024年
对2014年了
对2014年
我昨天好奇Transformer什么时候得奖
因为还要等三年
OK,2014年,让你们介绍一下,得奖两篇论文
对,得奖两篇Paper
因为其实平时的话,它一般都是只评出
一篇Paper作为这个 Test of Time的
但是今年就是选中了两篇
因为这两篇都是重量级的
而且非常 inferential 的
然后其中一篇呢,就是 Ian Goodfellow 的一个 GAN
这个是《对抗生成网络》
然后第二篇呢,就是《Sequence to Sequence》
是 Ilya Sutskever 作为一作的
也是对于这个NLP
其实他是做这个 Machine Translation
当时是做 Machine Translation
对那个还是在大语言模型
就是LLM出来之前
对
了解
那这两天
现场我们没有料到 Ilya 会出现的
对我们本来还以为就是 Ian Goodfellow会来
对
但是 Ian Goodfellow 因为他有那个Long Covid
所以他就做了一下 Remode
他 Covid 后遗症
然后跟我们远程的连了个线
做了一下这个Remote的一些分享
然后是由他的这个合作者来分享这个Paper本身
但 Ilya 是亲自来了
做了一个还挺重磅的分享
对,那你给大家分享一下他的这个
从你的角度来看
因为你之前在这个领域里面待的时间比较久
对 Ilya 的分享是什么理解的
对,是
他其实首先先回顾了一下这十年的一些工作
把原先的那个当时获奖的那篇Paper
这个资料他就照搬过来了
然后他其实我觉得他那个
我后来其实在这个社交媒体上也看到了
很多大家在评论说是不是说 Ilya 传达的这个信息就是
这个 pre-training 就大概这样了 就 Hit Walls 了
然后这个 Scaling Laws 就也许就可能不能再 Persist 了
这是我在有些社交媒体上别人的某一些解读
但我觉得它其实也并不是完全是传达这样的意思
我觉得 more like 就是传统的无监督的这个 pre-training
因为语料的关系
但这个语料因为是在
他就说因为我们就只有一个internet
对吧
因为这个internet这种数据已经被exhaust
但是呢
就所以呢
他他觉得如果是要靠这个预训练
而且是要靠这个数据来做的这个预训练
来这个就是 improve 这个大模型的这个performance
可能就到了一个瓶颈了
对吧
但是然后他有讲到
其实可以通过不一样的方法
比如说
比如说他们agents
或者说是合成数据
嗯
对吧
来这个来就是更进一步的
把这个 scaling law
carry on下去
嗯
对
这个这个是我得到的一个
比较重要的这个
我觉得他提到的意识
嗯
提到了意识
这个
哦提到了
对
提到的意识
那他提到的这个意识我觉得是在是不是在这个
他在分享这个 super intelligence
就是 what's coming next
而且是 longterm
对然后他就提到了
why not
对吧
就是因为
如果意识有好处
对如果意识有好处
我们为什么不能
其实在我记得在大概12月初的时候
Hinton他其实也分享过类似的一个
他是说主观体验
就是基础的一个主观体验
因为人的意识可能
但也是种学说嘛,分为可能基本的一些
主观体验和比较高级的一些主观体验
但是Hinton说,其实如果我们
只考虑比较基本的主观体验的话
比如说,他大概说了一个主观体验,
这个产生一个过程
就说,一个AI,他通过自己的推理,
在思考对一个事情产生的认知
和这个reality到底是怎么样的
其实这中间可能是会有些gap
当他也理解到这一点的时候
他就相当于产生了一个他自己主观的一个想法
然后Hinton当时就说可以把这个主观的这个体验
来作为一个我们所认识的
也不是我们所认识吧
就是给这个AI赋予所谓的这个意识
但这个意识其实就是可以通过计算来达到的
对我正好我在前两周的时候看到写了一个
Suddon 教授是吧
Suddon
Rachel Suddon
他写了《苦涩的教训》
《苦涩的教训》
这个很有名是吧
OpenAI 所有员工都要必读是吧
然后他做了一个采访
阿尔伯塔大学的一个AI的采访
他说到了这个意识可能是什么
他就说可能就是目标
就是我的目标
所有的目标可以通过算法把所有的小目标
组合会形成一个更加抽象的目标
比如说我现在想拿起这杯水
这是我的目标
我现在就要喝它
周围有有好多好多的小目标
然后它的算法会涌现出
结合起来结合起来涌现出
然后会形成一个我想上大学
我想干一个更加抽象的工作
这样的目标
它就知道如何达成了
它理解有目标、能做plan
还能反思
他就把这个定义成这个意识了
对他也是这是高级意识活动
对这个已经是比较高级意识活动
就已经能plan了已经能什么了
对
我刚才说的那个还只是一个主观的体验
对
他其实没有完全把他上升到这个哲学的层面
只是说可以通过计算达到的
对
就是这个比较是比较浅层的一个
就是主观体验比较浅层的一个意识
因为他们就不想把他上升到太高的
一个哲学的高度上去说这个事
对anyway
不过最终还是分不开
分不开了嘛是吧
结果 AI 再往后面走
解释不了 就哲学了嘛
是吧
因为大家都在研究思维嘛
思维是什么
或者智能是什么
最后只能用哲学解释了
对
就跟昨天我看到中文互联网上面
有 Ilya 那一张ppt截图
是吧
那个
预训练到头了
Pre-training 到头
然后 Ilya 其实现场并没有这样讲
他其实没有这么讲
他只是说
可能是说
ppt有误导是吧
对她可能只是说
就是我们这个hardware还是有的
然后我们这个infrastructure
就是这个模型的 complexity
也还能 goes up
但是data确实是
它用了个data is the new fossil fuel in the future
就是像现在的这个世界
就是这个石油
就是我们的这个 fossil fuel
是吧
就可以让这个有电有车
但是可能未来让我们模型更powerful的是
就是这个数据
这个数据的这个多样性
甚至是这个 fine grain 的程度
是不是这个精细的程度是吧
比如说我们现在只知道
做数学是这样想
但是或者说这个人对这事情是这样子的感觉
但其实我们现在连人类的感觉都没有Capture
刚才Jay就说到人的这种感觉
其实我们连感觉都没有Capture的
在现在的模型里
所以我觉得说
更不要说到还有很多Biological的数据
的这个 Fine Grain 的程度
其实我们也一样没有去 Capture 到
我记得 Ilya 分享了一个智力和重量的脑部的 Mass
后面有一个人提问也提问了这个问题
你们可以分享一下这个观点
我记得当时是一个是 Mammal 的
对吧
是一个Mass 是多少克
就是是人体多少克
然后那个纵作标是那个脑部的
然后就相关的一个linear的一个关系
然后一个是mammal的
还有一个是非人类的灵长类
还有一个是类人的灵长类
然后那个类人灵长类
它的斜率就会高一些
对
所以我感觉它就是
感觉上它做了一个类比
或者说是有点像inspire大家去想
有可能我们目前所探索的 Scaling Law
可能是 based on 某些 Factors 的
就是刚才我们说的比如说 Data Computing
还有这个模型本身对吧
虽然比如说 Data 可能 hit 到一定的 Wall
当然我们还可以就是通过这个合成数据来继续
Continue下去这个trend
但是也许还有另外的不同的发展路径
不同于我们现在所掌握的这些Factors
有可能去开发这些,就是扩展这些 factor
能够达到另外的一个就是 scaling law
所以其实就是说我们到底是在scale什么
我记得他之前也还做过一个演讲
他说 what are we scaling here
所以我觉得他其实是想来inspire大家
就是觉得大家不要被这些我们现在
就是 existent 的這些 scaling factors
scaling law 的這些 factors 去鎖這個局限住
看看是不是還有可能
我覺得全篇都在講
Pre-train
你們不要鎖在這個上面了
你不要鎖在 pre-train 的這個上面
對對對
全篇都在講這個意思
但是下一步要做什麼呢
我肯定不能告訴你們
那也沒有
我覺得他也說了一些
我覺得反正他的意思說在自然界中
就是這個人的這個身體
跟這個腦子的這個ratio
是有一個 linear relationship
但是也不是说脑子最大的就是最聪明
因为咱们人的脑子肯定不是脑容量最大
就是体积肯定不是最大
所以他就是像
也还是就像你 imply 说
可能是有别的 reason 让我们现在人类的智能
其实是比其他动物更高的
就是他提到
我记得好像他没有写 ppt
比如说提到 reasoning
就是个推理的能力
好一些这种
或许他没有提到
但我想人的这种可以想象的能力
其实也是很厉害
就是你可以想象未来
然后你朝你这个想象去做
就好像你说有个目标
但可能这个目标是没有实现
可以是你想象的
所以我觉得这个可能在其他能力
包括就是推理能力
想象能力
这个也是我们可能值得去
就是模型下一步值得做的地方
但它确实提出了三个点
一个是这个agents
一个就是这个合成数据
Synthetic data
然后第三个就是这个
Inference time to compute
就是推理时间的这个运算的这种
这方面的这种 skilling
因為我當時覺得他放這個圖
還是有點心機的
什麼意思呢
因為就是灵长類
可能體重增加沒那麼快
但是那個脑容量就是很快
長的時候 智力長得很快
你看那個鲸鱼是吧
他長到那麼大
他也沒人類聰明對吧
然後呢
他其實如果說把體重變成我們的訓練數據
他說應該可以不用那麼多訓練數據
你也可以變得更聰明
應該是這個暗示
所以說
而且他說一句話就是說
可能我們現在的 pre-training 只是
让我们达到这种智力的第一步
他就说我们有可能还会在解锁这样的方法
他希望鼓励
因为这个是在他好像回答提问的时候
说应该是不是更多的去在大脑里面
探索到一些新的发现的时候
我们就能够有新的方法
对
但他其实也并没有具体说
因为他提出了比如说像 o1
对吧
o1 里面比如说有一些
做一些RL方面的一些平衡效率
就是探索和search的一些平衡
還有是 self verification
就你有一個 verifier
再去評價它
還有別的
還有一些什麼思維鏈的這些
但是它們它自己的這個公司
因為它其實也還是
雖然它是做這個safety的
這個 super intelligence
但它其實也是要做這個大模型的訓練的
但它雖然也沒有具體的提出
到底是用什么药
就没有透露他们想要去探索
scaling law
下一步该怎么走
他具体也没有说
对这个就给大家留下了遐想的空间
对正好接着这个话题
因为 Ilya 最终办
对今天媒体上都是他
所有的网络上他 就是拉来压轴的
对正好昨天周五
对我觉得从之前
OpenAI她最新release的模型
其实也大致可以验证这样
就是当时我记得是GP4出来之后
大家就觉得这个语料其实已经很大
模型也已经很大了
但其实当时他做一些很难的这种问题
比如说特别是数学需要多部思维的题目
他做的其实不是很好
后来我记得他不知道是出了O1还是O1mini
我知道 O1
然后他那个时候他的这个reasoning
就是他的这个推理能力就大步的往前
然后他训练模型
好像反正就网上说是
他也在训练模型的时候给了他很多
就是一步步如何去解这个题的这个步骤
而不是说没有结构的语料
挂丢了去
所以就说这个一步步如何去
拆解一个问题这个思路本身
就这个推理的本身可能确实是
下一个突破口
我相信现在只是很简单的一些
还有更深度推理肯定
所以我觉得这个真的是一个很值得
对正好在他这个话题后面
因为我近期
我不是这个行业的
不是这个AI这个专业的
所以我只能看到一些比较
通俗易懂的这种podcast分享
正好有两部
一个是采访 LeCun 教授的
最新的一期
特别长的一期
一个半小时两个小时左右了
应该是印度的一个企业家采访他的
他在里面讲到
他肯定要推销自己做的东西
他做的那个叫JEPA
JEPA架构
就是一个JEPA架构
就是一个更加像人脑一样的
结构的一个思维
这个算是架构的一个变化
对
然后他总是在鄙视自回归,但 Ilya 就是干自回归的
但是我觉得自回归里面,其实它能够足够的压缩数据,
Ilya 所有的采访都能够有一个现实世界
的投影在里面,其实它有世界模型的
但是LeCun教授就是说,他可能有他的这样的一些方法
来形成专门的世界模型,这是一个架构上的
然後另外一個也是在前面提到
Suddon教授在也是接受最近的一個Podcast採訪
因為他挺少教授採訪的
講了這個
現在我們叫做預學習
就是pretrain
其實他這邊一直在講的就是
要持續學習
持續的學習這個概念
後面他也鼓勵很多學生
要把精力放到後面去
他跟那個LeCun兩個一樣的
你們要把東西往後放
你做研究課題的時候
要往後放
在這個
在持续学习上面还有什么新的方法来解决问题
我觉得这两个应该就是
你说持续学习就是 continue learning
对对对 continue learning
包括后面的这种推理都算是持续学习的
包括计划能力
通过少量数据 样本数据来学习能力
对对吧
包括O1它也通过少量这种数据
你现在它不是做了一个后训练的一个
对
turning
对
这也是一种回放学习
包括就是suggest一些
模型可以选择不同的一些就是options
然后你可能可以选择其中一个
就是做一个这个 reward model
然后可以用这个 RL 来选择其中一个
然后再用另外一个模型去verify它
对
然后就是通过这么一步一步的
让本身的推理过程
就是更加的accurate
更加的reliable
那这个最新OpenAI放出来的
就是它不是要圣诞节前放12天直播吗
第三天還是第二天放了那個叫RL turning
就是在強化學習階段你去給它微調數據
reinforcement learning 強化學習階段
這個東西是不是應該是這個階段的一個成就
對對我其實我這個要打斷一下
我說的你說的這個第二天它是說是哪一個模型
就是在它第二天直播發了一個功能
就是你可以在強化學習階段去做 fine turing
但是你说的强化学习现在是指在后训练
后训练对 Test Time Compute
那是的就是用这个RL去做
因为一般的话我们在做这个fine turning 的时候
你可以用SFT就是supervised
也可以就是RLHF但是这是 human feedback
但这个就是RL
然后现在你说的这个有可能是指
不是有可能
你现在说的这个可能是指
就是在 test time compute 的时候
其实可能是我刚才刚刚描述的那个
就是先 propose
先给出一个 searched space
然后 generate 出来一些 proposals
然后给每个的都有一个 reward model
然后用 RL 的方法去选择一个最好的路径
然后再用一个verifier去verify它
ok了解
我感觉这个事情后面两面性
OpenAI用这种方式可以搜索到
更多专家领域的人类的思考过程数据
这个是
因为你要把你的很多数据传到去 Fine Turning
然后它没有我没有看那个界面
因为它的明年才开放明年年初才开放给研究机构公司
上面是不是它不承诺用这个数据来训练
或者说默认我先拿去训练
除非说你不让我用我就不用
那谁知道
因为我觉得之前也了解过一些朋友
现在其实训练数据就差很多专家人类的这个思考数据
过程数据
因为互联网上昨天 Ilya 说互联网上的这个
我们的互联网就一个
嗯
他说这个这一句我记得很清楚
Only one internet
所以所有的数据迟早要用完的
然后互联网上的数据有一个特点
它都是结果数据
嗯
没有人会把自己
没有任何过程的数据
对
所以说机器永远都是快
闪现出来
然后一个结果给你
对
就像他说的
就 point one second 对吧
对对对
所以说我觉得现在OpenAI就想有一个更加好的方法
去把我们的这种数据给收上去
然后它用了一个可以帮你强化的你的过程
我觉得这个事情要两面性啊
这也可能是他们那个陰谋是吧
采集更多数据
采集更多的专家的如何思考的这个step by step 的数据
对
OK了解
那我们正好其实我们一直在聊
刚才说数据没有了
完全顺着 Ilya 这次分享
就是我们碰到了踢到墙了嘛
可能 pre-train 踢到一部分墙了
但是后面还有好多方法
但是其实还有另外一个领域有智能
其实就是那也挺火的
就是叫做 spatial 的空间智能
因为之前我之前做podcast
我也给大家分享过一本书叫做
A Brief History of Intelligence
就是《智能简史》
这本书我跟所有人推荐
写得非常好
对于我这种半瓢水的人来看
我觉得特好
对然后它里面就讲到了
其实包括李飞飞最开始他在TED上演讲了去年
她也用了就是看见
生物为什么
寒武纪生物为什么大爆发
因为他们长了眼睛
有看见世界了就是智能的
有了这个Vision以后
然后大大的促成了这个
语言是什么时候才诞生的
语言是我们几十万年前才有的
但是眼睛看到的是两亿年前就有了
所以这有差不多两个多亿年的进化
从脊椎动到哺乳动物
脊椎动物有眼睛, 哺乳动物肯定有眼睛
没有哺乳动物没有眼睛
蝙蝠
对
视力非常差,只有发超声波
OK,所以说这个两亿多年的进化
实际上按照生物来看
它的要比语言久太多了
空间智能
所以说应该我个人
是我个人判断
专家在这里做的
我觉得是不是我们下一次这个
或者其他一个热点
或者说从不管是投资上来看
或者说是这个研究方案上来看
空间智能可能会意义很
还会大于语言模型
可能问的不对啊
对
我觉得就是
怎么说呢
这个问题有点大
所以你是觉得就是空间智能
会比语言模型
对智能的推动
发展
作用更大
那你指的这个作用更大是
就是以哪些 metric 来衡量的智能
这是我们要让一个真实的机械人物理设备
在物理世界中思考移动看行动
这个意义的
能够释放的我们劳动力市场人类
会比现在的语言模型对知识工作者释放还要更大
这是从经济价值上来考虑的
这是一种, 正好李飞飞分享了这个话题
要不再来给大家来概述一下李飞飞的观点
我觉得你要不要先说一下
要不 Sonya 来
我就随便分享一下
其实我觉得李飞飞
她这个
因为我其实之前有断断续续听一些这方面的东西
但是我觉得这次李飞飞给了一个
有种前世今生的一个overview的感觉
就是她从就是说我们从就是可能
现在是有这个语言模型是吧
然后到可能但是现在
其实如果我们要有一个这种
具身智能就是Embodied AI 的话
其实不但是只是有这个
Language 我们这个眼睛也得
也得有虽然我们有Vision但是这个
这个深度是不够的
还有就是这个手上的这种活动
所谓的 Destress 这个 Task
就我们人类的手是非常灵巧
但现在机器人的手其实也没有达到这个
然后还有就是这个Body
就比如说你知道这个东西看着很脆弱
你知道绕开的
但现在机器人不知道
他可能就
他就直接就撞去了
他可能就是无法知道
这是一个陶瓷碗
我撞到是有事的
但是这是一个什么玻璃瓶
这样的其实无所谓的
就他不会对这个
这是一方面
就是另外还有就是说
这个东西的材质
比如说这是一个陶瓷的碗
我他可能很大力就可以把它抓碎
所以他还有一个研究方向
是关于就是这种
好像这个材质的
texture material 那一类的
我记得他讲了
大概可能是五到六大类
但是大致就这样
所以他想要从各个方面去collect一些data
总的来说他就是想collect各方面的data
去建一个
那下一步就是什么
去建一个可以这个虚拟世界
就以前是大家说 digital twin
但她现在讲的是 digital cousin
就是说我建一个大致一样的环境去虚拟
那为什么要建一个这样的环境呢
就是因为这样才能让我们有一个模拟的世界
可以迅速的去演化
比如说要不然的话
你今天上午写个算法
可能周五大家一块
为了更好的generalization
对对对
你可以更快的泛化
那如果有个这样子的环境之后
那你就可能更快的泛化
那就能够快速
为什么医疗方面就说做的很慢
就是因为我们很难在人体上做
实验对
但其实3D也是的
如果您的这些人就是就随便去测试
这个既然成本也很贵
然后你这个反正就挺难去测试的
所以就说如果做一个虚拟世界
大家快速的去成本比较低的这种演化
可能这方面就很快的就会有突破
我觉得Meta在这上面应该做得很先进
Meta 算了, 我就不评判, 我不知道
Meta 也有一个很好的平台
反正 Metal 它也是一直之前花了很多做 Reality Lab
所以它肯定是在这个虚拟世界里面
包括触觉,手套,采集这个数据
我觉得除了李飞飞还有另外一家
很有名的公司就 Physical Intelligence
然后就是李飞飞公司叫 worldlab
对对对
然后 Physical Intelligence 他们前段也不是前段时间
可能就出了一个比较有名的东西叫 Pi
就 P0 就 Pi0
然后它里面就也是用了更多的这种手部的数据
去做它这个训练数据
就是因为我们现在人类的很多很多这种
比如说大家想要什么所谓的带娃啊
洗碗啊
可能都会涉及到非常多这个手的这个灵活性
好像包括工厂里面工作
如果这方面没有很精准的数据
比如说我们只有2D的这种数据
那其实可能还是远远不够去建所谓的孪生 Cousin
孪生表亲是
Digital Cousin
对
我听到李飞飞说 Digital Cousin
对
她解释了什么意思
对
就是说跟数字孪生有什么不一样的地方
因为数字孪生很早以前就说了是吧
对
他做那个 Omniverse 的时候
对
Jensen Huang
天天吹了几年牛逼的东西
但是确实在用了
所以李飞飞我觉得她特意用一个词法去分开
叫做 Digital Cousin
因为她可以在这个模拟的过程中
她可以把这个什么光线啊
材质啊颜色啊什么的
都可以把它稍微做一些
Rent Transition
就是不一样的
所以呢
所以你就会有一个泛化
可以去接受到
就是你其实真实的情况中没有接受到的东西
对
所以她才叫这个 Digital Cousin
意思就是说,不是完全一样的,只是有些相似的
但是就说这个,我觉得这个WorldLabs
它好像从它公布的这个 Demo 上来看
它就是想建立一个Digital World,但是呢,
其实它也是想把这个 Digital World
他其实在我说,建立一个对这个Digital World 的
这个 understanding 还有 reasoning
他不是说有三步走嘛,对啦,一开始是一个understanding
对这个3D世界的理解,然后再是reasoning,然后再是generation,
因为generation已经是相对来说比较高级的这个task嘛
然后呢他在这个3D的这个Warp里面
说不上来了
就说让我想想该怎么表述
可以可以
我一下就说他其实就是想在这个环境中
做一些脑仿真
因为说实话
就是做这个Robotics也好
然后像他做这个3D的这个world的建模一样好
是非常非常少真实的数据的
对非常少
然后你要去做这个采集这些数据的话
是cost是非常大的
对
所以呢
我们他现在才想的就是用虚拟的去就是建立这个world
对吧
然后你有了这个虚拟的world跟这个真实的world以后
那就变成一个 mixed reality 了
所以这个其实对做这个 virtual reality 或者XR这些应用是
以后就是会发挥非常大的作用的
包括就是包括之后可能还会对
游戏的设计
还有 3D models 的设计
对
都会包括这个建筑的一些
建筑的一些可视化的一些建筑
对
的工作可能也都会有非常成熟的一些支持
对
但是目前可能没有
我记得我之前大概看有些paper的时候
就说好像
它真是generate出来的这些东西其实也并不是一些mesh
所以它不是可programmable的
但是对对对
但是它有可能会在今后的工作中会慢慢的向这个迈进
因为当它如果是个mesh
如果是可programmable的话
就可以完全用在做追地的modeling的生成
和这个game的design了
那听上去它应该可以在游戏引擎的基础之上去生成
对它现在是mesh的
但是它现在这些Data是怎么做出来的
它就是不是Sim2Real嘛
那它其实就是用的这些仿真的平台做的
那仿真平台Meta也有一个
还有这个Sanford有一个叫Gibson
它在那个Slide上面好像我记得也有提过
还有就是Unity
对,Unity
还有就是UnrealEngine
还有就是 Issac SIM, 就是 Nvidia 的
但是 Nvidia 这个Issac SIM 主要是给机器人用的
对,但是SIM2REAL的话好像我也是问了一些,
因为我自己也不是做这个的,我也是问了一些这方面的一些专家
他们也就是说到SIM2REAL其实
有的时候在需要这个精度比较高的时候
它的效果其实也并不是那么的好,因为你要看你要这个仿真的
这个颗粒度这个精细度到底要到什么样的一个程度
但是他们说在目前在做SelfDriving的这个用这个SIM2REAL做还不错
SIM2REAL因为不用那么精细嘛
对现在已经是Commercialize这个SIM2REAL
而且SIM2REAL也不一定只是用在Embodied AI的
它就是在其他的这些数据中也是可以用这个SIM2REAL的
所以就是说其实数据采集是非常非常重要
也是非常有challenge的这么一环
嗯对了解OK那我自己理解下我做一个经常在做投资和看这个什么
投资市场的人来看呢在空间智能里面的公司
可以分成一种创业公司看像刚才像这个
这个派这样的是吧还有一些大公司在做的
这些大公司在做空间智能有推动性的
我个人第一感觉就是Tesla他在做这个因为FSD要导航嘛
但真实世界中移动它肯定是有很多基础的
而且当时我看到他发XAI的时候
还特意举了个例子
同样是看图
xAI 可以看到我的距离这么多公分过不过的距离
但其他的模型都看不到
不是因为他的车上装了
没有装这个
装了这个sensor
他的sensor他的数据和对别人不一样
这个当然是他吹牛逼的地方
这个也是Tesla和 xAI 合力的一个地方
它如果合力
应该一个语言模型一个FSD是一个自动驾驶
这两个东西是有合力的
至少数据上是可以合力的
因为其实是这样子,人类它的perception,就是李飞飞她也提到
就是说对于深度,其实我们是通过脑子去process这个东西的
就是我们看那个图片,我们用双目,然后测试
然后我们去脑部去合成说,这个大致是有多远的距离
但其实只是这样,我们人类也很难说
我看到这个图片我到底就有多远起码
而且更不要说其实我们也是会受到这个黑夜啊,雨水啊
各种情况的这个影响去判断这个距离的,但是就像Tesla
这个车上装了这个测距的话, 一是它有这个image的
第二就是它具体有测这个测距之后
它可以很好说
那这样子的图片情况下
所以大概的距离是怎么样
所以它有一个很好的这种数据
这样它就可以做一个更正确的这种
方式去做这个mapping
从2D到10D的3D的距离是什么
所以我觉得这方面它确实会有优势
然后第二个有这种需求的公司
大公司里面就是有Meta和Apple
因为你们都在做Meta也在做Metaverse
做这个眼镜做各种头显
然后苹果也在做这个东西
苹果谷歌也是啊今天出来的
对谷歌我发了第三个说的
因为谷歌还有点不一样
谷歌的模型是很厉害的
然后Meta因为至少
大家认识Meta和Apple
都是在做智能设备的
而且他们是在上面至少是领先的
至少Meta是最领先的
然后苹果现在出了VisionPro
他们戴上这个头盔之后
因为这个眼镜要和人类一样感知世界很重要
其实说这个眼镜里面
不需要有語言模型
但它得空間感知
就是我看到什麼地方
它也看到什麼地方
它能給我回饋
它看到什麼東西
這個物體得標出來它是什麼
或者說我怎麼躲避障礙物
或者怎麼樣
我覺得這個智能就應該裝在它的未來的
下一代的眼镜設備裡面
所以說這兩家公司應該會對這個投入的
但我知道 Meta 是有投入的
蘋果是什麼都不公開的
我們不知道它在幹什麼
但是在這個時代其實它有點吃虧的
因為其實很多研究者為了發論文
就是为了就是为了让别人知道我在干什么
但是苹果不发很多
Researcher 不去他那儿
但是也许他下一个公布也会是一个惊喜
对对对有可能会有惊喜
这也是我个人理解
这两家公司在做
然后正好就是第三家公司就是Google
Google它它的这个有
但是Google是万年老二
对这个做硬件的
它永远都是老二
它做的也是
做的手机也是的
做什么东西都是的
所以永远都摆在苹果后面
而且有很多失败的这些硬件
但是现在Google手上有一个很好的东西,有个Gemini
Gemini因为我们在开会的时候,正好
头一天正好发布了Gemini2.0
然后第二天我们就在一个SideEvent上面
Turing AI 的,看到 Jeff Dean 大概采访了半个小时左右
而且他自己评价了一下 Gemini
还有他们的Google的Vision是什么
要不你们谁来帮我分享一下,还记得吗
我要回想一下,其实我更,因为 Gemini 的分享
可能在很多网上的评论里有看到过
但我其实还挺感兴趣他之前分享的一些
他分享他是当时怎么在 Google Brain 做的这个 DisBelief
你们还记得吗 记得 记得
因为那个时候我记得好像后来这篇文章后来又诞生了Cat
不知道大家还有没有这个印象GoogleBrain当时做了个CatProject
然后跟吴恩达老师 Andrew Ng 一起
当时他说 Andrew Ng 当时也是加入了Google Brain
然后他跟那个 Jeff Dean 还有那个团队一起合作
然后做了Disbelief
然后这个Disbelief
这个名字起的还挺Sarcastic
因为是 Distributed Belief Networks
但是人家就把它弄成 Disbelief
因为 Disbelief 其实是不相信的意思
但其实肯定很多人
他也是确实不相信这个路径
因为那个时候他们可能想做一个Unsupervised Learning
以前都是 Supervised Learning
2012年,2012年因为已经是AlexNet
所以肯定是在2012年之前的
对,然后他们那个时候,我具体忘了他们是用什么样的模型,
可能是某种 Version of the Alt Encoders
对,但是也是很大的一个模型,好像也有One Billion parameters
对,然后那个时候,他可能,我记得他当时在这个分享会的时候
另外那个Turing的那个CTO不就说嘛
他说你当时是不是也已经有想到这个Scaling Law, 对吧,就是说因为
记得, Ilya 也是2014年,2012年,2013年这几年想到了
对,就是说其实很多时候都是殊途同归嘛,对吧,很多BrightMinds
可能就是在相近的这个时候,可能想到了差不多的这个ideas
对但是然后那个 Jeff Dean 当时
就他们整个团队啊包括跟这个
这个 Andrew Ng 一起的对然后他们
也create了一个这样的就是这个叫做
Disbelief Network
然后是一个Auto encoder Variation
然后很多的parameters也是1Billion的parameters
然后我记得他当时说是
16000个Cores好像在1000个
具体的数字不是记得特别清楚啊
然后好像是1000个
是吧16000个这个Cores
然后在1000个这个Cores上面run的
然后他们确实好像是Observe到了这个ScalingLaw
因为他们好像还大概是Record了
就是大概比如说我多少层数的时候
或者多少数据的时候
它的性能的提高是怎么样
比如说这个Average下降是怎么样的
然后他就在从中里面
他就也是有了这个ScalingLaw的这个雏形的这个idea
因为我之前其实不知道这个事
他讲得很生动
就还挺有意思的
那确实真的是殊途同归了
因为 Ilya 也是在差不多 2012 2013 2014年
就是在那个时候
然后他们也是在Google也是在这个时候
但是那个时候 Ilya 是在Google
Ilya 应该是2015年
我其实具体几几年我不太
Ilya 当时他 Sequence to Sequence 那篇文章
其实也是在Google写
2014年的时候
那可能是2015年的时候
应该是2015年的时候去到这个OpenAI的
OpenAI我记得啊
2015年的那个 NeurIPS 上面
成立的
开这个会的时候
对对对对
我相信其实他们可能在之前做研究的时候
很多人都也会想到这个 Scaling Law 的事情
但是其实有很多的 scientists 都也是不相信的
对
然后后来我觉得就是那个
Ilya 也是因为就是到了这个OpenAI之后
然后他们自己在做一些模型
然后这个GPT就出来了嘛
GPT出来是2017年
不是GPT我说错了
Transformer出来的时候
然后他那个时候就觉得
这个Transformer可以用过来
而且Transformer本身也是可以上Scalable的
对
然后他就觉得我们可以就去
把这个就用
用在这个就拿了这个GPU嘛
对就拿了老黄的 GPU
然后就开始大规模的开始做这个pre-training了
我觉得这个也叫巧合,也叫注定
大家同时不同的人在同一时期注意到了这个
原来通过scale我就能够变得更聪明,变得更厉害
而且正好 Ilya 他在宣布SSI前后
她好像推荐过一篇论文叫做《柏拉图假说》
柏拉图洞穴寓言的假说
其实就写了结论就是你不管用什么样的方法
不管用什么样的东西
你只要数据量足够了
最终这些模型的智能就都殊途同归了
就是说聪明的人都是一样的
你这总结得很好
傻的人都各式各样
对,就是小模型他傻的各式各样
但是大模型
只要这个模型的 capability 就足够好
对
它可能就汇聚到一个点
所以它解题方法就汇聚到一个点上去了
对
我最终
而且它还有两个
它有天生的简洁性
它就用了自然选择
总是选最简单的一样
它就选择了一个最简单的方法
解决这个问题
但是有时候人类不会这样解决问题
但是神经网络面训练出来
它就会这样解决问题
然后呢
还有一个
我记得在OpenAI有个研究员是在去年发了一篇博客
他写的博客写得很好玩
他写的现在这些模型公司叫DeepMind
或者叫做Gemini
或者叫做Claude
或者叫OpenAI
GPT
其实你们都不能叫算法的不一样
你们都叫不同的数据集
你们不管有什么算法
加暴力计算之后
训练完之后
其实都差不了多少
差别的就是数据集
就是在数据集上的差异决定模型能力不一样
所以这个数据有多重要
对
所以当我们现在这个数据
就是濒临到已经快要被exhaust的时候
对怎么样想办法去合成这个数据
而且有些数据可能还比较narrow的
我们怎么样看看
是不是可以再generate出一些out of distribution 的数据
使得它更加分布化
才能够使它最后的结果更加泛化
但是其实一直生成数据有意义吗
其实我对这个问题是挺什么的
因为其实生成的数据
也是 based on 以前的数据
其实相当于它这个多样性
还有包括这个失真性
其实也是一个问题
就是说生成的数据
它只是把数据量变大
但它这个意义有多大
其实我本身我自己是抱有同样的怀疑
这个论文里面有讲
那篇论文
柏拉图假说里面
就是它会回归到一个均值上面去
它没有突破
没有突破
所以我觉得就不能完全从现有的这个数据
再去生成数据
其实要突破它这个现有的这个distribution
因为不然的话你其实问不到一些新的
对吧
新的一些features也好
新的distribution也好
所以现在其实 NeruIPS 里面也会
我记得有一些 talk
也会workshop也会讲
就是怎么样可以突破这个限制
然后使得这个生成的
这个 synthetic data
对对对
质量更高嘛
对吧
但比如说所谓就是 out of
现在的 distribution
那就是跟现在的大部分数据不一样
那你怎么知道这个很不一样的数据是
是个有意义的数据还是是一个hallucination
是一个不靠谱的数据
所以这个其实我觉得也是挺大的一个问题
对就是怎么样解决这些都是目前现有的
就是大家正在研究的问题
对还有一块就是刚才我们讲到的回顾一下
我们讲到好多了一下子讲到
刚才我们其实都忘记讲这个 Jeff Dean后面这个 Gemini
因为我刚才没关系
我先总结一下
我先给大家总结一下
因为这个四十多分钟需要总结一下
因为我们最开始就从我们讨论
这个 NeurIPS 的这个会开始
大家这个会的历史介绍了一下
然后介绍了第一个神秘嘉宾
最重要的神秘嘉宾
Ilya 出现了
然后 Ilya 就是抛出了一个概念
就是这个pre-train end
就被人解读了
但实际上还没有
他也给出了很多方法
然后实际上就提到了数据的重要性
然后我们顺着这个就讲到李飞飞讨论,在这个语言,
除了语言模型之外,我们是不是还有其他的方式来提升智能,
那就是空间智能,空间智能的意义,我们也聊了很多嘛,
她也是着重讲了这个数据,对,
就是数据,就是数据,其实我们就回到数据上来,,
我们刚刚从李飞飞这边再又跳到了这个 Jeff Dean
这个过去我们通过同一期发现了这个ScalingLaw是有效的
就是在那个时候不同的团队都发现了,
然后发现了这个规律了,是吧,然后
正好我在这个地方我提到了数据的
数据也提到了一篇论文吧
讲到了和论文和一个OpenAI研究员的一篇blog
其实大家唯一的区别就是数据的区别
没有什么区别
因为你的算法都会去同
最后你只要算力足够大
你的算法对模型的影响其实不大了
那么回到最后论文里面有写
写得也很明确的
我们现在差物理世界的数据
对我们差物理
那就整理回到这前面去了
为什么要做空间智能
为什么要去做这个
所以你看李飞飞教授当时提到的
有各种各样
在一张slides上写的
对各种各样的
它就是收集数据的这些
它有五个项目
对Behavior
ObjectFolder
对这些都是在收集
这些不同的类别的数据
有些可能是
就是家用是吧
就是家居的一些
家居的話它涉及到就是
有behavior也有材質
然後手部
手部的那個可能是 dexcap
反正就是
圍繞著一系列的
不同的這個
還有一些 motioncap 的數據
但可能大家會覺得說
我們其實有很多數據啊
我們說有很多圖片嗎
有很多video為什麼這些不能用
要不然 Jay 也可以展开讲讲为什么这不也是数据吗
为什么不能用
为什么要专门去采集是吧
对
我们的这个 video 数据
对
就说我觉得这个video数据而且是2D的数据
嗯
就是说很多的时候你2D的数据
需要去直接infer你这个3D的结构啊什么的
其实不那么容易
嗯
包括其实像Sora还有这些所有的这个视频生成的这些平台
之前的出来有很多我记得当时 Jim Fan说
好像就是一个
就是一个这个
叫什么图片生成引擎
还是什么物理世界这个
但是它其实
究竟是怎么做的我们也不知道
但他们现在在生成
就是
李飞飞教授在做这个
搜集数据的时候
包括去用
SIM2REAL这些平台去做这些模拟
仿真的时候那些数据
很多其实就是从Unity Generate出来的,包括这个Isaac平台,
NVIDIA的Isaac平台Generate出来的
但是你这个Generate出来这些数据的时候
其实就用Unity和用Unreal Engine去Generate这个数据的时候,
它其实已经有隐含的这个物理的
这个特性在后面了,就是由这个Physics law来drive,来生成这些数据的
所以这些数据的生成,它本身其实是有,怎么说呢,
就是有internal representation, hater representation
在那边的,已经有我们整个world的representation在里面的
但是我们实际上的这个video的数据,包括images啊,
包括YouTube上的2D,它是没有3D的隐含的,在里面要自己去infer的,
这个是我觉得不一样点,所以现在我们之前
也不是碰到了一些,就是有一些scientist
他们也就讲到他们现在想自己搭建一些室内的棚子
然后放了很多的就是ABN的这种
他们用这个ABN的
姿态图也是这么做的
放了很多这个SmartSensors
然后这些SmartSensors
有些是可能通过这个摄像头
来Capture
就是你各个有可能是这个关节或者手
对一些这个Movement
有些可能就是直接戴一个手套
对吧
这个手套有些是 Optical Sensor
有些是这个Magnetical Sensor
然后来Capture这个
那这些数据就是比较Native的这些3D的一些数据
然后用它来生成的这个场景
其实我感觉就是有蕴含着更多的3D的
Representation和 Physics Law在里面
这个非常好
正好顺着这个数据
其实我现在我们说最后一个话题
Gemini 发布了2.0
2.0我觉得是我感受了一下
我觉得它是一个把多模态做得非常好的
就是刚才说的这个数据3D数据或者什么数据
其实它现在能够原生的听语音输入
原生的视频和图片输入
然后还能够做原生的声音输出和图像输出
它不是和以前那种我图像模型要用Diffusion model
然后N合一了
它全部都 Training 进去了
或者说模态合了一块
它这个非常强大了
而且现在唯一的一款模型是这样的
这没有了, N合一模型
所以说这个意义,你觉得在哪儿
对,而且我今天好像还看到
就是他们谷歌好像有一个平台叫AndroidXR
对,然后它跟这个三星一起有合作
打造了一款,也是一款眼镜吧
我不知道它里面应该用的也是Gemini
后面所有的模型
它用了那个对,那个叫做VR的一个系统
对对对,但是这个系统后面应该也是有包括这个
所以我是觉得就是谷歌好像就是在全方位的在发力
然后包括就是有个Astra是吧
Project Astra 还有 Project Marina
一个是个人助手,还有一个是Computer Use
就有点跟这个Claude 的 Compute rUse比较类似的
但是它可能focus on在这个web的navigation上面的
另外那个可能是 focus on desktop 和web
就是可能更加
Scope可能相对来说更加大一些
对
但是我觉得反正就是
谷歌就是感觉就是在
就是各个产品或者各项
就是都是在
这两天股票涨得很好
是吧
因为量子芯片又突破了是吧
它把那个比特位
比特位变多了
然后把Error 的这个rate也是降低了
对
所以说这个这两个突破挺大的
而且它的模型
我觉得突破也挺大的
其实它在一定程度上
已经超过了OpenAI的这个水平了
在某些地方
我不是说所有的
我觉得谷歌模型不好的地方
就是数据集采的不好
可能是他们太官僚的问题
我听到一些故事太官僚
导致数据集采购的时候被人骗
对
不太不像小公司嘛
就每一个东西进来之后
我们会比较注意
比如说上次出现的那个
把华盛顿画成黑人
还有各种很搞笑的问题
比较早期的事情
作为他们的救火去了
所以这个我觉得Google
但是它还是有最好的技术积累
绝对的
Talents绝对是顶尖的
而且它有还关键
我们在这次活动上面还碰到了
SemiAnalysis
Dylan Patel
对
他的一篇文章
在去年的时候叫做 GPU rich
然后写了半天就写了Google
他算过之后市场上GPU最多的就他
就是他了
他自己还能造TPU
对自己还能造TPU
他把TPU算进去了
转换成GPU了
转换成这个GPU
而且他TPU便宜嘛
对对对
量产
而且他只给自己用
非常 cost friendly
从那个时候我就
但股票还很便宜嘛那个时候
作为投资来说
我觉得当时我就押注 Google 嘛
对对
我觉得google是一家挺好的公司
就是大公司病
这个没办法
对
这个是一个问题
但是我觉得它的研发实力和人才储备
和整个技术的规模效益
还有一个它有用户规模效益
对它有
它随时可以把用户
我觉得这个是世界上三家公司
用规模效益最好
这就是Google
然后Mata
然后Apple
还有Tesla
Tesla它是车
它的用户没有那些普通用户那么多
对
Tesla可能已经在过五年
它有Twitter
对我忘了
Twitter也跟它们有不太一个数量
也不在一个数量级上面
但是最厉害的还是
但是 xAI 有这些推特的数据
其实也是非常Advantages的
对我个人来看
这个时代在做AI做模型
因为它太依赖于数据了
而且太依赖于这个公司
对于普通用户的触达的能力了
因为数据会让你模型变得更好
第二个是我通过用户的投放能力
我让更多人用
这两个合起来
所以说对于小公司来说
简直是灾难
就是灾难,所以说在这个时代可能只有大公司和小公司
小公司可能长不成成中间规模的公司
但是也还是挺佩服那些非常有情怀的小公司的
我觉得还有一些中型公司
可能做agent的公司,如果做的好的可能
比如说像什么Databricks 跟 SalesForce,
这种可能它会成为中层公司
就他们也是直接触达客户,但是就像他
可能不掌握这个未来的电力啊,大模型
所以他要源源不断地,他们也不掌握模型了
他要源源不断的去买电
但是因为他有这些独特的数据
所以他再加上去买完这个电
他还是能够成为一个中等规模
但他不是一个电力公司
对这个是我自己脑子面前建的一个模型
怎么看这些公司
还有AI时代的这个公司的变化
就是说那我觉得并不是小公司不好
小公司挺好的
如果说AI能够让一个团队人效提高五倍
那我就会把人员减少五倍
那我同样赚同样的利润
比如说agent多了之后
agent多了之后
那我员工就少了
利润自然就高了,这个是很合理的一个
所以说,你看这个 Jeff Dean 最后
其实 Jeff Dean 也说了是
Gemini 要做Agent,然后要做多模态,做到最好
然后同时2.0里面还有一个代码
Coding 那是他们最重要的
那么接下来,包括 Ilya 在他很牛逼的一页PPT上面写的
第一个就是 Agentic, 这个能力
所以他也,我记得 Ilya 当时也有提到,
就说现在的这些 agent flow,或者这个agents,
其实能力可能还是有限的,太弱了,对对对
真正以后就是会有非常强大的这个agents出现
那时候才是可能是一个质的飞跃,对,就是非常streamlines的
而且,他说,我记得他好像提到
跟这个copilot还有什么一般的chatbot有些区别
就是像这些copilot跟目前的这些
一些助理的话,可能其实跟人的交互还是蛮频繁的
但是他说以后如果真正的这个代理
其实是有非常强大的自主性和这个引导能力的
所以他可能就更加的自动化,而且更加的有自主性
然后能够帮你识别出你可能
因为根据你的历史或者什么的
可以帮你更加有效的去完成很多的任务
而且有更强的理解力跟这个环境的互动的能力
而且 Sonya 应该注意到了
这一次餐会的公司里面做Agent是最多的
论文可能没注意
因为论文不会写这么具体
写这么应用
但是公司里面是最多的
这一次
而且应该可能未来会更多
那么这个里面就涉及到了
其实我觉得
如果说对于效率提高来说
Agent是一个必经之路
或者我们就往这个方向来走
那么其实最后一个话题
就是JeffDean他有人问的这个话题
或者他最后一个话题讨论的就是
这个东西
会对首先会对这个
Programmer
coding人员的替代
然后再对普通的这个工作的替代
它是一步步来的大家怎么看这个话题
最后收尾一下
对职业的替代的问题
对其实我觉得其实李飞飞当时也有说过一个
她说是 replace human
还是
然后就把那个 replace 给划掉了 还是empower
就是 augment
是一个意思的
对所以其实
很多的时候他
是帮助我们去 take care of 一些我们平时,
比如说非常 routine 的工作
或者就是不需要我们进行很深度思考的工作,它帮我们去做好了
当然了,它其实甚至也可以做一些相当
有深度的,包括像coding,对不对
所以我觉得它可以把我们很多的时间给free out出来
让我们可以更focus on再做深度的思考
或者更加有visionary
更加creative
更加innovative
在这个工作上面去
对
不知道你们怎么想
我觉得对
就
我觉得可能大家确实要找一些
自己更感兴趣的东西去做
可能就是在未来
觉得感觉好像
你的眼神就要偷偷地流露
一种悲观是吧
没有没有
我觉得不是悲观
可能其实未来的社会是一个
物资非常富足的一个世界
因为可能无论从医疗护理
你看现在医院里面
就是说可能觉得还护士不够呀
或者担心没有人来陪你聊天啊
你就可能什么脑子就怎么了
但其实我觉得未来其实可能或者说
你有甚至说你可能就是
你心里有很多事情
带你不方便跟无论是coworkers跟你朋友讲
但是心理医生都很贵
我觉得可能就是未来世界是
这些可能都不再是一个问题
就是只要有算力啊这都不是问题
所以呢我觉得可能就是
人类会有更多的这个自由的时间
去做怎么去
做自己喜欢的事情
但是我觉得这个社会的整个
它其实会overall是有更多的财富的
而且有更多的闲暇时间的
就是取决于怎么去分配了
然后那么剩下这些闲暇时间
跟这些物资是吧
衣服不会缺
对
因为你工厂可以
所以说到我们整体的人再贫困的人
他的baseline也提高了
对
基线提高了
就 Bill Gates 自己说了
刚才说你们未来世界怎么样
就是你们每个人都过上像我这样子的生活
Bill Gates 自己就说过了
所以说可能我觉得就是大家要找一个自己真正感兴趣的事情
然后一直一直做下去
可能就是因为你做的多
然后你想多
然后你可能还是会在这个领域就是发光发亮
但是这个不是说蹦着说
哎
我能获得更多的什么财富啊
或什么之类的
可能真的是你的这个兴趣
然后driven
然后甚至可能会对这种梦有一些突破
可能真的是要靠兴趣
或者这个是对就是就是我们昨天晚上还在讲
但是可能很多人都会选择躺平
因为当这个物质极大丰富的时候
因为可能你也不需要去陪你爸妈了
给他什么护理
因为可能其他人可以护理
你这个衣服什么的
对食物也充足
我的观念就是
反正最后一个话题
我们要总结一下
我的观念我觉得人得更像人
是
人要提供人和人之间的连接价值
因为这个机器代代替不了
就打个比方说
Salesforce的公司都用agent實現的
那它還是得有銷售
還是有很多公司在
那麼銷售就負責把人搞定
然後剩下的全部agent做的好了
對
所以人和人的連接價值還是非常重要的
而且在數字化時代的人的連接
你可以有很多方式做
physical的做也可以digital的方式做
在線上做
然後在線下做都行
而且我相信人肯定不是最logical的
人本身build的機制就不是logical的
所以說如果我們很logical
那我們今天很多東西就是很economic的行為是吧
对,但我们其实很经济学就说我们也不是logic
所以我觉得未来也是需要人与人之间的链接
可能就回归到这个是最有价值的一个东西
我不知道 Jay 怎么看
对,所以说
没有没有,我完全同意你们所说的
对啊
对,就是人要实现自己的价值
包括实现自己的价值
在一切很多的这个基本的这个生活
满足
对对对,都已经很OK的情况下面
就像每个人都发了一个什么 UBI 什么的
但是但是人要但是我觉得人追求自己的价值
一个是追求他自己想要实现的一些东西
对的意义还有一个就是人的温情就是跟大家的这个
跟大家和跟这个世界的一些深度的连接
所以所以我才觉得就是在将来的世界啊
不是说大家一定要都去学这个理科啊或者是就学STEM啊什么的
其实更多的时候比如说去探索自然呀探索这个ART呀探索太空
只要你想探索这个太空有无缘无尽的问题
就是去拓宽自己的这个探索的边界吧
对吧会使得整个就自己的这个整个人的一生就会过得更加的充实
因为我有时候说有时候说我们不是每个人都想探索太空
那就就是做好就是人与人之间的链接
或者就做一点自己感兴趣的事情
反正怎么样其实我觉得都挺好的
就是爱画画就画画
就是爱照顾人就照顾人
爱带小孩就带小孩
用一句话总结一下
最后我总结一下
这个工作的问题就是说
首先人类总有解决不完的问题
所以说我们永远都会有工作的
什么工作而已是吧
什么工作而已
好吧
那我们今天就先聊到这
感谢两位参加给大家总结这一次活动
我觉得挺有意义的
好吧
谢谢大家
謝謝 indigo
